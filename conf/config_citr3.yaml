defaults:
############## TRAIN ###################################
  - train/config: splade
  - train/data: citr
  - train/model: splade
############## INDEX ###################################
  - index: msmarco
############## RETRIEVE ################################
  - retrieve_evaluate: all
############### FLOPS ##################################
  - flops: msmarco    

# Direct PARAMETER setting SIGIR 23  CONFIG DENSE 32 NEG NO DISTILLATION
config:
  train_batch_size: 5
  regularizer:
    FLOPS:
      lambda_d: 5e-3
      targeted_rep: rep
      reg: FLOPS
    L1:
      lambda_q: 5e-3
      targeted_rep: rep
      reg: L1
  checkpoint_dir:  ??
  index_dir: ??
  out_dir: ??
  fp16: true
  hf_training: true
  max_length: 512
  config.lr: 2.0e-5 
  tokenizer_type: naver/splade-cocondenser-ensembledistil
  matching_type: splade

hf:
  training:
    resume_from_checkpoint: false
    ddp_find_unused_parameters: false
    fp16: true
    logging_steps: 100
    save_strategy: epoch
    dataloader_drop_last: True
    num_train_epochs: 5
    warmup_ratio: 0.01
    mse_margin: false
    weight_decay: 0
  model:
    dense: false
    shared_weights: true
  data:
    distillation: false
    n_negatives: 8
data:
  type: jsonl
  TRAIN:
    DATASET_PATH: /traindata/datasets/embeddings/splade/mgaiduk/v0/splade_v0_5m_train/1pos8randneg_part5.jsonl
  VALIDATION:
    DATASET_PATH: /traindata/datasets/embeddings/splade/mgaiduk/v0/splade_v0_5k_val/1pos8randneg.jsonl

init_dict:
  model_type_or_dir: naver/splade-cocondenser-ensembledistil
  model_type_or_dir_q: null
  freeze_d_model: 0
  agg: max
  fp16: true
